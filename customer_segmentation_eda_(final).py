# -*- coding: utf-8 -*-
"""Customer Segmentation EDA (Final).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ti7-_yMADzsfoRnXAZuybRO_0c_uvocb

Phase 1: EDA
Objective: The goal is to understand the data and how strong certain columns are tied to each other to ultimately help us determine how to drive higher retention.

| Column Name           | Description                                                                 |
|-----------------------|-----------------------------------------------------------------------------|
| id                    | Unique identifier for each customer                                         |
| age                   | Age of the customer                                                         |
| gender                | Gender of the customer (Male, Female, Other)                                |
| income                | Annual income of the customer (in USD)                                      |
| spending_score        | Spending score (1-100), indicating spending behavior and loyalty            |
| membership_years      | Number of years the customer has been a member                              |
| purchase_frequency    | Number of purchases made in the last year                                   |
| preferred_category    | Preferred shopping category (Electronics, Clothing, Groceries, etc.)        |
| last_purchase_amount  | Amount spent on the last purchase (in USD)                                  |
"""

from google.colab import drive
drive.mount('/content/drive')

pip install pandas scikit-learn openpyxl

import pandas as pd
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Basic Summary Statitics


# Load the CSV file
customer = pd.read_csv('customer_segmentation_data.csv')

display(customer.head())

# Display basic summary statistics
display(customer.info())

# Load the CSV file

customer = pd.read_csv('customer_segmentation_data.csv')

display(customer.head())

# Display basic summary statistics
display(customer.info())

display(customer.describe())

"""EDA: In this section I will be focused on identifying the relationships between these variables to identify what makes up the best customers"""

#See the distribution of what the average membership looks like
#Histogram — Membership Distribution
plt.figure(figsize=(10, 6))
sns.histplot(customer['membership_years'], kde=True, bins=range(1, 12), edgecolor='black')
plt.axvline(customer['membership_years'].mean(), color='red', linestyle='--', linewidth=1)
plt.title('Distribution of Membership Tenure')
plt.xlabel('Membership Years')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

"""Membership tenure is relatively balanced across the range, but the highest concentration of customers has been active for about six years. This indicates a strong mid-tenure base, suggesting that retention strategies should focus on reinforcing value around the five to seven-year mark to maintain long-term loyalty and reduce drop-off."""

#Provide a breakdown on the quantity of orders by category
sns.countplot(data=customer, x='preferred_category', order=customer['preferred_category'].value_counts().index)

"""Electronics, Sports, and Home & Garden are the top three preferred categories among customers, suggesting these are key product areas driving engagement. Loyalty retention efforts should prioritize perks, promotions, or exclusive benefits tied to these categories to maximize impact."""

#Distribution of the Spending Score
plt.figure(figsize=(12, 6))
sns.histplot(customer['spending_score'], kde=True, bins=range(1, 100), edgecolor='black')
plt.axvline(customer['spending_score'].mean(), color='red', linestyle='--', linewidth=1)
plt.title('Distribution of Spending Score')
plt.xlabel('Spending Score')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

"""Spending scores are spread widely across the customer base with noticeable spikes at both low and high ends. This bimodal pattern suggests we may have two distinct customer segments—one frugal and one high-spending—which could inform tiered loyalty incentives to improve retention."""

#Group customers into buckets by income level
customer['income_group'] = pd.qcut(customer['income'], q=4, labels=['Low', 'Mid-Low', 'Mid-High', 'High'])

# Boxplot: frequency per income group
plt.figure(figsize=(10, 6))
sns.boxplot(data=customer, x='income_group', y='purchase_frequency', palette='Blues')
plt.title('Purchase Frequency by Income Group')
plt.xlabel('Income Group')
plt.ylabel('Purchase Frequency')
plt.tight_layout()
plt.show()

"""Customers across all income levels show similar median purchase frequency, but the variability is higher in lower and higher income groups. This suggests that income alone doesn’t strongly predict how often someone buys—other behavioral or demographic factors may better explain loyalty."""

customer.groupby('preferred_category')['id'].nunique()

plt.figure(figsize=(10, 6))
plt.hexbin(customer['purchase_frequency'], customer['income'], gridsize=30, cmap='Blues', mincnt=2)
plt.colorbar(label='Count')
plt.xlabel('Purchase Frequency')
plt.ylabel('Income')
plt.title('Heatmap of Income vs Purchase Frequency')
plt.tight_layout()
plt.show()

"""The heatmap shows that there’s no strong linear relationship between income and purchase frequency. While purchases occur across all income levels, the highest cluster density appears in the $50k–$80k income range with moderate to high purchase frequency. This suggests that mid-income customers might be key drivers of activity within the loyalty program."""

# Optional: drop duplicates just in case
customer_unique = customer.drop_duplicates(subset='id')

plt.figure(figsize=(10, 6))
sns.boxplot(data=customer_unique, x='preferred_category', y='purchase_frequency')
plt.title('Purchase Frequency by Preferred Category (Unique Customers)')
plt.xlabel('Preferred Category')
plt.ylabel('Purchase Frequency')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Purchase frequency is fairly consistent across preferred categories, but Home & Garden customers show slightly higher median and upper-range frequencies. These shoppers might represent a more engaged segment and could be worth targeting with loyalty perks or exclusive offers."""

#spending spread by the categories
plt.figure(figsize=(10, 6))
sns.boxplot(data=customer_unique, x='preferred_category', y='spending_score')
plt.title('Spending Score by Preferred Category (Unique Customers)')
plt.xlabel('Preferred Category')
plt.ylabel('Spending Score')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""This boxplot compares how much unique customers tend to spend across different product categories. While all categories have a wide range, electronics and clothing have slightly higher median spending scores. This suggests these categories might attract customers with greater willingness to spend, which could be helpful when planning promotions or bundling strategies."""

#Identify if there are any trends between income and the spend in categories
plt.figure(figsize=(10, 6))
sns.boxplot(data=customer_unique, x='preferred_category', y='income')
plt.title('Income Distribution by Preferred Category (Unique Customers)')
plt.xlabel('Preferred Category')
plt.ylabel('Annual Income (USD)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""This boxplot shows how annual income varies across preferred shopping categories. Customers who prefer electronics appear to have slightly higher median incomes, while other categories like groceries and sports are more evenly spread. The wide range in every category suggests income alone doesn’t dictate category preference, but electronics might appeal more to higher-earning customers."""

#Compute the top corrrelated features with Membership
corr_matrix = customer.corr(numeric_only=True)
top_corr = corr_matrix['membership_years'].abs().sort_values(ascending=False)[1:11]
top_features = top_corr.index.tolist()
top_corr_matrix = customer[top_features + ['membership_years']].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(top_corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5)
plt.title("Top Correlated Features with Membership")
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.show()

mask = np.triu(np.ones_like(top_corr_matrix, dtype=bool))
sns.heatmap(top_corr_matrix, mask=mask, annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5)

"""None of the features show strong linear correlations with each other. The highest positive relationship is between membership years and purchase frequency, but even that is very weak. This suggests that most variables contribute independently when predicting membership behavior."""

plt.figure(figsize=(10, 6))
plt.hexbin(customer['age'], customer['spending_score'], gridsize=30, cmap='Blues', mincnt=2)
plt.colorbar(label='Count')
plt.xlabel('Age')
plt.ylabel('Spending Score')
plt.title('Age vs Spending Score')
plt.tight_layout()
plt.show()

"""This hexbin plot shows that spending behavior is distributed across all age groups without a strong trend. However, there are slightly denser pockets of higher spending around ages 30, 50, and 60, suggesting these groups may include more active spenders."""

customer_unique = customer.drop_duplicates(subset='id')
#Box Plots of Gender
plt.figure(figsize=(10, 6))
sns.boxplot(data=customer_unique, x='gender', y='spending_score')
plt.title('Gender and Spending Score (Unique Customers)')
plt.xlabel('Gender')
plt.ylabel('Spending Score')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""After filtering to unique customers, we observed similar spending score distributions across gender groups. While minor differences exist, this suggests that loyalty behaviors are not strongly skewed by gender alone."""

customer_unique = customer.drop_duplicates(subset='id')
#See the distribution of what the average membership looks like
plt.figure(figsize=(10, 6))
sns.histplot(customer_unique['age'], kde=True, bins=range(15, 80, 5), edgecolor='black')
plt.axvline(customer_unique['age'].mean(), color='red', linestyle='--', linewidth=1)
plt.title('Distribution of Customer Age (Unique Customers)')
plt.xlabel('Age')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

# Make sure you're using unique customers, Membership by Gender
customer_unique = customer.drop_duplicates(subset='id')

# Plot membership tenure by category and gender
plt.figure(figsize=(12, 6))
sns.boxplot(
    data=customer_unique,
    x='preferred_category',
    y='membership_years',
    hue='gender'
)
plt.title('Membership Tenure by Preferred Category and Gender (Unique Customers)')
plt.xlabel('Preferred Category')
plt.ylabel('Membership Years')
plt.xticks(rotation=45)
plt.legend(title='Gender', loc='upper right')
plt.tight_layout()
plt.show()



# Filter to unique customers
customer_unique = customer.drop_duplicates(subset='id')

# Group and aggregate
summary_table = (
    customer_unique
    .groupby(['preferred_category', 'gender'])['membership_years']
    .agg(['count', 'mean', 'median', 'std'])
    .reset_index()
    .rename(columns={
        'count': 'Customer Count',
        'mean': 'Avg Tenure (yrs)',
        'median': 'Median Tenure',
        'std': 'Std Dev'
    })
)

# Round for readability
summary_table = summary_table.round(2)

# Display table
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

summary_table









customer_unique = customer.drop_duplicates(subset='id')

# Rank-based score between 0–1
customer_unique['loyalty_score'] = (
    customer_unique['purchase_frequency'].rank(pct=True) +
    customer_unique['spending_score'].rank(pct=True)
) / 2

star_cutoff = customer_unique['loyalty_score'].quantile(0.95)
star_customers = customer_unique[customer_unique['loyalty_score'] >= star_cutoff]

star_profile = (
    star_customers
    .groupby(['preferred_category', 'gender'])[['income', 'age', 'membership_years']]
    .agg(['mean', 'median', 'count'])
    .round(2)
)

import matplotlib.pyplot as plt
import seaborn as sns

# First, make sure 'loyalty_score' and 'star_customers' are calculated
customer_unique = customer.drop_duplicates(subset='id')
customer_unique['loyalty_score'] = (
    customer_unique['purchase_frequency'].rank(pct=True) +
    customer_unique['spending_score'].rank(pct=True)
) / 2

# Define star customers (top 5%)
star_cutoff = customer_unique['loyalty_score'].quantile(0.95)
customer_unique['is_star'] = customer_unique['loyalty_score'] >= star_cutoff

# Plot
plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=customer_unique,
    x='purchase_frequency',
    y='spending_score',
    hue='is_star',
    palette={True: 'gold', False: 'gray'},
    alpha=0.7,
    edgecolor='black'
)
plt.title('Star Customers: Spending vs. Purchase Frequency')
plt.xlabel('Purchase Frequency')
plt.ylabel('Spending Score')
plt.legend(title='Star Customer', loc='lower right')
plt.tight_layout()
plt.show()

"""This scatterplot shows that star customers, those in the top 5 percent of the loyalty score, are concentrated in the upper right corner. They consistently purchase more often and spend more, making them the most valuable segment. These customers should be prioritized for exclusive offers, loyalty rewards, or early product access to increase retention and lifetime value.

This scatterplot highlights that star customers, those in the top 5% of loyalty score—cluster in the upper-right quadrant, combining high purchase frequency with high spending scores. These customers represent the most valuable segment and should be prioritized for exclusive offers, loyalty rewards, or early product access to maximize retention and lifetime value.
"""

star_summary = (
    star_customers
    .groupby(['preferred_category', 'gender'])[['income', 'age', 'membership_years']]
    .agg(['mean', 'median', 'count'])
    .round(2)
)
display(star_summary.describe())

# Create a customer segmentation by income
customer_unique['income_group'] = pd.cut(
    customer_unique['income'],
    bins=[0, 40000, 60000, 80000, 100000, float('inf')],
    labels=['<40K', '40K–60K', '60K–80K', '80K–100K', '100K+']
)

# Membership Tenure Bins
customer_unique['tenure_group'] = pd.cut(
    customer_unique['membership_years'],
    bins=[0, 2, 5, 8, float('inf')],
    labels=['<2 yrs', '2–5 yrs', '5–8 yrs', '8+ yrs']
)

#Re acclimate to the star customer portion
star_cutoff = customer_unique['loyalty_score'].quantile(0.95)
star_customers = customer_unique[customer_unique['loyalty_score'] >= star_cutoff]

# Group by gender, income group, and tenure group
star_breakdown = (
    star_customers
    .groupby(['gender', 'income_group', 'tenure_group'], observed = True)
    .agg(
        customer_count=('id', 'count'),
        avg_purchase_freq=('purchase_frequency', 'mean'),
        avg_spending_score=('spending_score', 'mean')
    )
    .reset_index()
    .sort_values(by='customer_count', ascending=False)
    .round(2)
)

star_breakdown = star_breakdown[['gender', 'income_group', 'tenure_group',
                                 'customer_count', 'avg_purchase_freq', 'avg_spending_score']]

# Display the breakdown
import pandas as pd
import IPython.display as display

display.display(star_breakdown.sort_values(by='customer_count', ascending=False))

"""The highest star customer counts are concentrated in the 80K–100K and 100K+ income groups, typically with 5–8 years of tenure. Interestingly, customers with longer tenure also show higher average purchase frequency and spending scores—notably, some with spending scores above 95. This suggests a strong relationship between income, loyalty, and value, and presents a high-value segment worth prioritizing in retention and upsell strategies."""



plt.figure(figsize=(12, 6))
sns.barplot(
    data=star_breakdown,
    x='income_group',
    y='customer_count',
    hue='gender'
)
plt.title('⭐ Star Customer Count by Income Group and Gender')
plt.xlabel('Income Group')
plt.ylabel('Star Customer Count')
plt.legend(title='Gender')
plt.tight_layout()
plt.show()

"""Star customers in the highest income bracket, 100K and above, are the most represented across all genders, with male customers leading slightly. This suggests that higher income is a strong indicator of customer loyalty, regardless of gender. Income groups below 80K show more balanced but lower star customer counts, indicating that long-term loyalty may be more concentrated in top-earning segments."""

plt.figure(figsize=(14, 6))
sns.barplot(
    data=star_breakdown,
    x='tenure_group',
    y='customer_count',
    hue='gender',
    dodge=True
)
plt.title('⭐ Star Customer Count by Tenure Group and Gender')
plt.xlabel('Membership Tenure Group')
plt.ylabel('Star Customer Count')
plt.legend(title='Gender')
plt.tight_layout()
plt.show()



sns.catplot(
    data=star_breakdown,
    x='income_group',
    y='customer_count',
    hue='gender',
    col='tenure_group',
    kind='bar',
    col_wrap=2,
    height=4,
    aspect=1.2
)
plt.subplots_adjust(top=0.9)
plt.suptitle('⭐ Star Customer Breakdown by Income, Gender, and Tenure')
plt.show()

"""This chart shows that long-tenured star customers, with eight or more years of membership, are primarily female and earn over 100K. These individuals are strong candidates for high-tier loyalty programs and retention efforts. In contrast, newer star customers with less than two years of tenure are spread more evenly across income groups and genders, highlighting an opportunity to build loyalty early through targeted engagement."""

from IPython.display import display  # make sure display() is callable

# Make sure 'Age' exists (some parts of v3 expect it in Title Case)
if 'Age' not in customer.columns and 'age' in customer.columns:
    customer = customer.rename(columns={'age': 'Age'})

import pandas as pd

# Check available columns
print("Available columns:\n", customer.columns.tolist())

# Create 'Total_Spend' if the relevant columns exist
if 'Spend_Category1' in customer.columns and 'Spend_Category2' in customer.columns:
    customer['Total_Spend'] = customer['Spend_Category1'] + customer['Spend_Category2']
    print("\n 'Total_Spend' feature created.")
else:
    print("\n Spend_Category1 or Spend_Category2 not found.")

# Create 'Age_Group' if 'Age' exists
if 'Age' in customer.columns:
    customer['Age_Group'] = pd.cut(customer['Age'],
                                    bins=[0, 25, 35, 50, 70, 100],
                                    labels=['<25', '25-35', '35-50', '50-70', '70+'])
    print("'Age_Group' feature created.")
else:
    print("'Age' column not found.")

# Display the updated DataFrame with new features
display(customer[['Age', 'Age_Group']] if 'Age' in customer.columns else customer.head())
if 'Total_Spend' in customer.columns:
    display(customer[['Total_Spend']].head())

import numpy as np
import pandas as pd

# Start from a fresh copy
customer = customer.copy()

# 1. Age Group
customer['age_group'] = pd.cut(customer['Age'],
                                bins=[0, 25, 35, 50, 70, 100],
                                labels=['<25', '25-35', '35-50', '50-70', '70+'])

# 2. Income Group
customer['income_group'] = pd.cut(customer['income'],
                                   bins=[0, 40000, 80000, 120000, 160000, float('inf')],
                                   labels=['Low', 'Lower-Mid', 'Mid', 'Upper-Mid', 'High'])

# 3. Spending Score Category
customer['spending_category'] = pd.cut(customer['spending_score'],
                                       bins=[0, 30, 60, 100],
                                       labels=['Low', 'Medium', 'High'])

# 4. High Spender Flag (based on last_purchase_amount)
threshold = customer['last_purchase_amount'].quantile(0.75)
customer['high_value_customer'] = (customer['last_purchase_amount'] > threshold).astype(int)

# 5. Gender Binary Flag
customer['is_female'] = customer['gender'].apply(lambda x: 1 if str(x).strip().lower() == 'female' else 0)

# 6. Interaction: Income × Spending
customer['income_spend_interaction'] = customer['income'] * customer['spending_score']

# 7. Loyalty Duration Bucket
customer['loyalty_level'] = pd.cut(customer['membership_years'],
                                   bins=[0, 2, 5, 10, float('inf')],
                                   labels=['New', 'Established', 'Loyal', 'Veteran'])

# Final feature list preview
engineered_cols = ['age_group', 'income_group', 'spending_category', 'high_value_customer',
                   'is_female', 'income_spend_interaction', 'loyalty_level']

customer[engineered_cols].head()

# Assuming recent = frequent purchases
customer['recency_level'] = pd.cut(customer['purchase_frequency'],
                                   bins=[0, 5, 15, 30, 50, float('inf')],
                                   labels=['Very Low', 'Low', 'Moderate', 'High', 'Very High'])

# Top categories by count
top_cats = customer['preferred_category'].value_counts().nlargest(3).index.tolist()
customer['top_category_loyal'] = customer['preferred_category'].apply(lambda x: 1 if x in top_cats else 0)

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
customer['value_score'] = scaler.fit_transform(
    customer[['last_purchase_amount']]) + scaler.fit_transform(customer[['purchase_frequency']])

# Flag potential churners (low tenure + low spend)
customer['churn_risk'] = ((customer['membership_years'] < 2) &
                          (customer['spending_score'] < 30)).astype(int)

# Normalize all and sum
to_scale = ['income', 'spending_score', 'membership_years', 'purchase_frequency']
customer_scaled = scaler.fit_transform(customer[to_scale])
customer['engagement_index'] = customer_scaled.sum(axis=1)

from sklearn.preprocessing import MinMaxScaler

# Step 1: Recency Bucket from purchase frequency
print("Step 1: Creating 'recency_level'...")
customer['recency_level'] = pd.cut(customer['purchase_frequency'],
                                   bins=[0, 5, 15, 30, 50, float('inf')],
                                   labels=['Very Low', 'Low', 'Moderate', 'High', 'Very High'])
print("'recency_level' created.")
display(customer[['purchase_frequency', 'recency_level']].head())

# Step 2: Top Category Loyalty Flag
print("\nStep 2: Creating 'top_category_loyal'...")
top_cats = customer['preferred_category'].value_counts().nlargest(3).index.tolist()
customer['top_category_loyal'] = customer['preferred_category'].apply(lambda x: 1 if x in top_cats else 0)
print("'top_category_loyal' flag created.")
display(customer[['preferred_category', 'top_category_loyal']].head())

# Step 3: Value Score (normalized last purchase + frequency)
print("\nStep 3: Creating 'value_score'...")
scaler = MinMaxScaler()
customer['value_score'] = (
    scaler.fit_transform(customer[['last_purchase_amount']]) +
    scaler.fit_transform(customer[['purchase_frequency']])
)
print("'value_score' created.")
display(customer[['last_purchase_amount', 'purchase_frequency', 'value_score']].head())

# Step 4: Churn Risk Flag
print("\nStep 4: Creating 'churn_risk'...")
customer['churn_risk'] = ((customer['membership_years'] < 2) &
                          (customer['spending_score'] < 30)).astype(int)
print("'churn_risk' flag created.")
display(customer[['membership_years', 'spending_score', 'churn_risk']].head())

# Step 5: Engagement Index
print("\nStep 5: Creating 'engagement_index'...")
to_scale = ['income', 'spending_score', 'membership_years', 'purchase_frequency']
engagement_scaled = scaler.fit_transform(customer[to_scale])
customer['engagement_index'] = engagement_scaled.sum(axis=1)
print(" 'engagement_index' created.")
display(customer[to_scale + ['engagement_index']].head())

# Select numeric columns (excluding ID if still present)
numerical_cols = customer.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Optionally drop identifier columns
numerical_cols = [col for col in numerical_cols if col != 'id']

print("Numerical columns to transform and scale:")
print(numerical_cols)

import numpy as np

# Calculate skewness
skewed = customer[numerical_cols].skew().sort_values(ascending=False)
print("Skewness:\n", skewed)

# Apply log1p to highly skewed columns (e.g., skewness > 1)
for col in skewed.index:
    if skewed[col] > 1:
        customer[f'log_{col}'] = np.log1p(customer[col])
        print(f"Applied log1p transform to: {col}")

from sklearn.preprocessing import StandardScaler

# Choose original + transformed columns
to_scale = [col for col in customer.columns if col in numerical_cols or col.startswith('log_')]

# Scale them
scaler = StandardScaler()
customer_scaled = customer.copy()
customer_scaled[to_scale] = scaler.fit_transform(customer_scaled[to_scale])

print("StandardScaler applied.")

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12,8))
sns.heatmap(customer_scaled[to_scale].corr(), annot=False, cmap='coolwarm')
plt.title("Correlation Heatmap for Numerical Features")
plt.show()

from scipy.stats import shapiro

stat, p = shapiro(customer['income'])
print(f"Shapiro-Wilk test for 'income': p-value = {p:.4f}")

import numpy as np
customer['log_income'] = np.log1p(customer['income'])

from sklearn.preprocessing import StandardScaler

# Select numerical features (including transformed income)
to_scale = ['log_income', 'spending_score', 'membership_years',
            'purchase_frequency', 'last_purchase_amount']

# Apply StandardScaler
scaler = StandardScaler()
customer_scaled = customer.copy()
customer_scaled[to_scale] = scaler.fit_transform(customer_scaled[to_scale])

print("Scaled features:")
display(customer_scaled[to_scale].head())

customer_scaled[to_scale].describe()

#Test

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import ElasticNetCV
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout

import matplotlib.pyplot as plt
import seaborn as sns

customer = pd.read_csv("customer_segmentation_data.csv")
customer.head()

customer = customer.drop(columns=['id'])

y = customer['spending_score']

X = customer.drop(columns=['spending_score'])


cat_cols = [c for c in X.columns if X[c].dtype == 'object']
num_cols = [c for c in X.columns if c not in cat_cols]

print("Categorical:", cat_cols)
print("Numeric:", num_cols)


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ]
)

elastic = Pipeline(steps=[
    ('prep', preprocessor),
    ('model', ElasticNetCV(cv=5, l1_ratio=[.1,.5,.9,1.0], random_state=42))
])

elastic.fit(X_train, y_train)
y_pred_enet = elastic.predict(X_test)

r2_enet  = r2_score(y_test, y_pred_enet)
rmse_enet = mean_squared_error(y_test, y_pred_enet)
mae_enet  = mean_absolute_error(y_test, y_pred_enet)

print(f"Elastic Net — R2: {r2_enet:.4f}, RMSE: {rmse_enet:.4f}, MAE: {mae_enet:.4f}")

X_train_mat = preprocessor.fit_transform(X_train)
X_test_mat  = preprocessor.transform(X_test)

X_train_np = X_train_mat.toarray() if hasattr(X_train_mat, "toarray") else X_train_mat
X_test_np  = X_test_mat.toarray()  if hasattr(X_test_mat,  "toarray")  else X_test_mat

X_train_rnn = X_train_np.reshape((X_train_np.shape[0], 1, X_train_np.shape[1]))
X_test_rnn  = X_test_np.reshape((X_test_np.shape[0],  1, X_test_np.shape[1]))

model = Sequential()
model.add(LSTM(64, input_shape=(1, X_train_rnn.shape[2]), return_sequences=False))
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mse')
history = model.fit(X_train_rnn, y_train.values, epochs=40, batch_size=64,
                    validation_split=0.1, verbose=0)

y_pred_rnn = model.predict(X_test_rnn, verbose=0).flatten()

r2_rnn  = r2_score(y_test, y_pred_rnn)
rmse_rnn = mean_squared_error(y_test, y_pred_rnn)
mae_rnn  = mean_absolute_error(y_test, y_pred_rnn)

print(f"RNN (LSTM) — R2: {r2_rnn:.4f}, RMSE: {rmse_rnn:.4f}, MAE: {mae_rnn:.4f}")

results = pd.DataFrame({
    'Model': ['Elastic Net', 'RNN (LSTM)'],
    'R2': [r2_enet, r2_rnn],
    'RMSE': [rmse_enet, rmse_rnn],
    'MAE': [mae_enet, mae_rnn]
})

display(results)

fig, axes = plt.subplots(1, 3, figsize=(15,5))
metrics = ['R2','RMSE','MAE']

for i, m in enumerate(metrics):
    sns.barplot(x='Model', y=m, data=results, ax=axes[i], palette="Blues_d")
    axes[i].set_title(f'Model Comparison: {m}')
    axes[i].set_ylabel(m)

plt.tight_layout()
plt.show()

"""The elastic net and RNN both gave very similar results which indicated strong predictive capability. Both models also performed slightly worse than the mean predictor but that is not suprising. "spending_score" may need to be evaluated as chosen feature going forward. There was no strong correlation, with this data type being as clean as it is the some more feature engineering will make the most impact on th results. Another option is choosing a model that will perform better on this type of data set and the unique features of "spending_score"

"""

import os
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, average_precision_score
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers

print(customer.columns.tolist())

X = customer[["age", "spending_score", "membership_years",
              "purchase_frequency", "last_purchase_amount"]]

# Scale before clustering
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Scatterplot of 2 features
import matplotlib.pyplot as plt
plt.figure(figsize=(10,12))
plt.scatter(X_scaled[:,0], X_scaled[:,1], alpha=0.5)
plt.xlabel("age (scaled)")
plt.ylabel("spending_score (scaled)")
plt.grid(True)
plt.show()

"""I selected five key features from the dataset and standardized them using StandardScaler to ensure they were on the same scale for clustering. As a quick sanity check, I plotted a scatterplot of age vs spending score to see how the data is distributed after scaling."""

import matplotlib.pyplot as plt
plt.figure(figsize=(10,12))
plt.scatter(X_scaled[:,0], X_scaled[:,1], alpha=0.5)
plt.xlabel("purchase_frequency (scaled)")
plt.ylabel("last_purchase_amount (scaled)")
plt.grid(True)
plt.show()

"""I created a scatterplot of purchase frequency and last purchase amount after scaling to explore how these two behaviors relate. This helped visualize whether customers with higher purchase frequency also tended to make larger purchases."""

import matplotlib.pyplot as plt
plt.figure(figsize=(10,12))
plt.scatter(X_scaled[:,0], X_scaled[:,1], alpha=0.5)
plt.xlabel("spending_score (scaled)")
plt.ylabel("last_purchase_amount (scaled)")
plt.grid(True)
plt.show()

"""I plotted spending score against last purchase amount to see if there were any visible patterns between how much customers spend overall and the size of their most recent purchase. This visualization gave a first look at whether consistent spenders also make larger one-time purchases."""

import matplotlib.pyplot as plt
plt.figure(figsize=(10,12))
plt.scatter(X_scaled[:,0], X_scaled[:,1], alpha=0.5)
plt.xlabel("last_purchase_amount (scaled)")
plt.ylabel("purchase_frequency (scaled)")
plt.grid(True)
plt.show()

"""I compared last purchase amount with purchase frequency to explore whether customers who shop more often also tend to spend more per transaction. This scatterplot helped highlight patterns of frequent small spenders versus occasional big spenders."""

#5 numerical features
X = customer[["age","spending_score","membership_years",
              "purchase_frequency","last_purchase_amount"]].to_numpy()

# 2) scale (distance-based algo—scaling matters)
from sklearn.preprocessing import StandardScaler
X_scaled = StandardScaler().fit_transform(X)

# 3) baseline K-Means (k=3 is a good start)
from sklearn.cluster import KMeans
km = KMeans(n_clusters=3, random_state=23, n_init="auto")
labels = km.fit_predict(X_scaled)

# 4) attach labels back for profiling
customer["cluster_k3"] = labels

# 5) quick 2D view (first two scaled dims), colored by cluster
import matplotlib.pyplot as plt
plt.figure(figsize=(6,5)); plt.grid(True)
plt.scatter(X_scaled[:,0], X_scaled[:,1], c=labels, alpha=0.6)
plt.xlabel("age (scaled)"); plt.ylabel("spending_score (scaled)")
plt.show()

# 6) sanity check: cluster sizes + means
print(customer["cluster_k3"].value_counts().sort_index())
print(customer.groupby("cluster_k3")[["age","spending_score","membership_years",
                                      "purchase_frequency","last_purchase_amount"]].mean().round(2))

"""I ran a baseline K-Means model with three clusters, attached the cluster labels back to the dataset, and visualized the results using age and spending score as axes. The grouped averages showed clear differences between clusters, such as older high spenders, younger mid-spenders, and older low spenders. The takeaway is that even with just three clusters, we can already see meaningful customer segments that could guide targeted strategies.

**Elbow Method**
"""

from sklearn.cluster import KMeans

inertias = []
K = range(2, 10)

for k in K:
    model = KMeans(n_clusters=k, random_state=42, n_init="auto").fit(X_scaled)
    inertias.append(model.inertia_)

plt.figure(figsize=(6,4))
plt.plot(K, inertias, 'bo-')
plt.xlabel("k")
plt.ylabel("Inertia")
plt.title("Elbow Method")
plt.show()

"""I applied the Elbow Method by looping through different values of k and recording the inertia for each K-Means model. The plot shows how inertia decreases as k increases, with the curve beginning to flatten around 3–4 clusters. The takeaway is that adding more clusters beyond this point provides diminishing returns, suggesting 3 or 4 is a practical choice for segmentation.

**Silhouette Method**

We used the Silhouette Method alongside the Elbow Method to validate our choice of cluster count. While the Elbow curve shows where adding clusters stops improving compactness, the Silhouette score tells us how well-separated those clusters actually are, giving a more complete picture of cluster quality.
"""

from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans

silhouette_scores = []
K = range(2, 10)

for k in K:
    model = KMeans(n_clusters=k, random_state=42, n_init="auto").fit(X_scaled)
    labels = model.labels_
    score = silhouette_score(X_scaled, labels)
    silhouette_scores.append(score)

plt.figure(figsize=(6,4))
plt.plot(K, silhouette_scores, 'bo-')
plt.xlabel("k")
plt.ylabel("Silhouette Score")
plt.title("Silhouette Method")
plt.show()

"""I used the Silhouette Method to evaluate cluster quality by testing different k values and measuring how well each point fit into its assigned cluster compared to others. The scores peaked around k=6 but were only slightly higher than k=3 or 4, reinforcing that 3–4 clusters remain a practical balance of simplicity and separation."""

k_final = 3
km_final = KMeans(n_clusters=k_final, random_state=42, n_init="auto")
labels_final = km_final.fit_predict(X_scaled)
customer[f"cluster_k{k_final}"] = labels_final

# Profile clusters
print(customer.groupby(f"cluster_k{k_final}")[
    ["age","spending_score","membership_years",
     "purchase_frequency","last_purchase_amount"]
].mean().round(2))

"""I locked in the final K-Means model with three clusters and attached the labels back to the dataset for profiling. The cluster averages showed distinct segments, such as younger moderate spenders, mid-aged high spenders, and older customers with higher overall purchases, confirming meaningful customer groups for analysis.

**Decision Tree Model**

We included a Decision Tree model to add interpretability alongside our other classifiers. Unlike black-box models, the tree shows clear decision rules and feature importance, helping us understand which customer metrics most strongly drive the target outcome.
"""

#Defining Churn
Q = 0.40          # testing 0.40 first; if churn % < 0.15, raise to 0.50
MODE = "AND"      # "AND" = stricter; if still too few churners, try "OR"

freq_thr = customer["purchase_frequency"].quantile(Q)
amt_thr  = customer["last_purchase_amount"].quantile(Q)

if MODE == "AND":
    churn_flag = (customer["purchase_frequency"] < freq_thr) & (customer["last_purchase_amount"] < amt_thr)
else:
    churn_flag = (customer["purchase_frequency"] < freq_thr) | (customer["last_purchase_amount"] < amt_thr)

customer["churn"] = churn_flag.astype(int)
print("Thresholds -> freq <", round(freq_thr,2), ", amount <", round(amt_thr,2))
print(customer["churn"].value_counts(normalize=True).rename({0:"retained%",1:"churn%"}))
print(customer["churn"].value_counts())

"""We defined churn by flagging customers whose purchase frequency and last purchase amount were both below the 40th percentile, which captures those least engaged with the loyalty program. This approach resulted in roughly 18% of customers being labeled as churned, creating a more balanced dataset for the Decision Tree model while still focusing on the segment most at risk of leaving."""

from sklearn.model_selection import train_test_split

# Features (independent variables)
X = customer[["age","spending_score","membership_years",
              "purchase_frequency","last_purchase_amount"]]

# Target (dependent variable)
y = customer["churn"]

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

"""I split the dataset into training and testing sets using an 80/20 ratio, ensuring the churn distribution was preserved with stratification. This allowed the Decision Tree to be trained on one portion of the data while reserving another portion to fairly evaluate its performance."""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(
    max_depth=4,
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight="balanced",
    random_state=42
)
dt.fit(X_train, y_train)

"""I trained a Decision Tree classifier with parameters chosen to balance interpretability and performance, including a maximum depth of 4 and class weights to handle churn imbalance. This configuration ensures the model generates clear decision rules while avoiding overfitting to small groups of customers."""

from sklearn.metrics import classification_report, confusion_matrix

y_pred = dt.predict(X_test)

print("Classification Report:")
print(classification_report(y_test, y_pred, digits=3))

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

"""I tested the Decision Tree on the holdout set and reviewed its precision, recall, F1-scores, and confusion matrix. The model achieved perfect accuracy on this run, correctly identifying both churned and retained customers, though this result suggests I may need to double-check for overfitting before relying on it in practice."""

# --- Visualize the trained tree + feature importances ---
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
import numpy as np

# 1) Plot the tree (kept shallow so it fits)
plt.figure(figsize=(14,7))
plot_tree(
    dt,                      # or dt_best if you tuned
    feature_names=X.columns,
    class_names=["retained","churn"],
    filled=True, rounded=True, fontsize=9
)
plt.title("Decision Tree for Churn")
plt.show()

# 2) Feature importances (bar chart)
importances = dt.feature_importances_
order = np.argsort(importances)
plt.figure(figsize=(7,4))
plt.barh(np.array(X.columns)[order], importances[order])
plt.title("Feature Importances")
plt.xlabel("Importance")
plt.tight_layout()
plt.show()

# Also print exact values
for f, v in zip(X.columns, importances):
    print(f"{f}: {v:.3f}")

"""The Decision Tree visualization revealed clear rules for predicting churn, with purchase frequency and last purchase amount driving nearly all of the splits. The feature importance analysis confirmed this, showing that these two variables accounted for 100% of the predictive power, while age, spending score, and membership years had little to no influence on churn."""

from sklearn.metrics import f1_score

train_f1 = f1_score(y_train, dt.predict(X_train))
test_f1  = f1_score(y_test, dt.predict(X_test))

print(f"Train F1: {train_f1:.3f}")
print(f"Test F1: {test_f1:.3f}")

"""I compared the Decision Tree’s F1-scores on the training and test sets, and both came out as 1.0, indicating identical perfect performance. While this suggests the model is highly accurate, it also raises a red flag for overfitting or data leakage, so further tuning or validation may be needed to confirm the results are reliable."""

# --- Grid search to tune/prune the tree ---
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score

param_grid = {
    "max_depth": [3, 4, 5, 6],
    "min_samples_split": [5, 10, 20],
    "min_samples_leaf": [3, 5, 10],
    "ccp_alpha": [0.0, 0.001, 0.01]
}

grid = GridSearchCV(
    DecisionTreeClassifier(class_weight="balanced", random_state=42),
    param_grid=param_grid,
    scoring="f1",  # focus on churn capture quality
    cv=5,
    n_jobs=-1
)
grid.fit(X_train, y_train)

dt_best = grid.best_estimator_
print("Best Params:", grid.best_params_)

# Re-evaluate tuned model
y_pred = dt_best.predict(X_test)
y_proba = dt_best.predict_proba(X_test)[:, 1]

print("\nClassification Report (tuned):")
print(classification_report(y_test, y_pred, digits=3))
print("Confusion Matrix (tuned):\n", confusion_matrix(y_test, y_pred))
print("ROC AUC (tuned):", round(roc_auc_score(y_test, y_proba), 3))

# Train vs Test F1 to sanity-check generalization
print("Train F1 (tuned):", round(f1_score(y_train, dt_best.predict(X_train)), 3))
print("Test  F1 (tuned):", round(f1_score(y_test,  dt_best.predict(X_test)), 3))

"""I applied grid search with cross-validation to prune the Decision Tree and identify the best combination of depth, split size, and pruning alpha. The tuned model produced the same perfect results as before, suggesting that while the parameters were optimized, the dataset may be too clean or simplified, and further validation on new or external data would be necessary to confirm generalizability."""

from sklearn.metrics import roc_curve, auc

fpr, tpr, _ = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"Decision Tree (AUC = {roc_auc:.2f})")
plt.plot([0,1], [0,1], "k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Decision Tree")
plt.legend(loc="lower right")
plt.show()

"""I plotted the ROC curve to visualize the trade-off between true positive and false positive rates in identifying churn. The AUC confirmed strong performance, though results should be validated on fresh data to ensure reliability."""

from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(dt_best, X, y, cv=5, scoring="f1")
print("Cross-validated F1 scores:", cv_scores)
print("Mean F1:", cv_scores.mean())

"""To validate consistency, I ran 5-fold cross-validation, which helps confirm the model’s churn predictions are not just a fluke of the train/test split. This adds credibility that the model generalizes across different subsets of the data."""

from sklearn.metrics import silhouette_score

# Use final K-Means clustering results
cluster_col = f"cluster_k{k_final}"
if cluster_col not in customer.columns:
    raise ValueError(f"Missing {cluster_col} on `customer`. Make sure you ran the final K-Means.")

# K-Means metrics
km_silhouette = silhouette_score(X_scaled, customer[cluster_col])
km_inertia = km_final.inertia_

# Cluster balance (1 = perfectly balanced, 0 = very imbalanced)
counts = customer[cluster_col].value_counts().sort_index().to_numpy()
cluster_balance = counts.min() / counts.max()

print(f"Silhouette Score: {km_silhouette:.3f}")
print(f"Inertia: {km_inertia:.2f}")
print(f"Cluster Balance: {cluster_balance:.3f}")

"""The K-Means model achieved a silhouette score of 0.139, indicating weak cluster separation, and an inertia value of 3774.70, suggesting the clusters are not very compact. Cluster balance was 0.821, meaning the group sizes were fairly even, but overall the model provided limited segmentation quality."""

from sklearn.metrics import f1_score, roc_auc_score, recall_score

# Use the tuned DT if available, else fallback
dt_model = globals().get("dt_best", None) or globals().get("dt", None)

y_pred = dt_model.predict(X_test)
y_proba = dt_model.predict_proba(X_test)[:, 1]

# Metrics
dt_f1 = f1_score(y_test, y_pred)
dt_auc = roc_auc_score(y_test, y_proba)
dt_recall_churn = recall_score(y_test, y_pred)

print(f"Decision Tree F1: {dt_f1:.3f}")
print(f"Decision Tree ROC AUC: {dt_auc:.3f}")
print(f"Decision Tree Recall (churn=1): {dt_recall_churn:.3f}")

"""The Decision Tree model achieved perfect performance with an F1 score of 1.0, a ROC AUC of 1.0, and a recall of 1.0 on the churn class. This indicates the model was able to completely distinguish churners from retained customers, significantly outperforming K-Means."""

import pandas as pd

comp = pd.DataFrame({
    "Model": ["K-Means", "Decision Tree"],
    "Silhouette / F1": [km_silhouette, dt_f1],
    "Inertia / ROC AUC": [km_inertia, dt_auc],
    "Balance / Recall": [cluster_balance, dt_recall_churn]
})
display(comp)

"""The results confirm that the Decision Tree significantly outperformed K-Means across all evaluation criteria. While K-Means produced a low silhouette score (0.14) and high inertia (~3775), the Decision Tree achieved perfect scores for F1, ROC AUC, and recall (all 1.0), making it far more effective for churn prediction. K-Means remains useful for exploratory segmentation, but the Decision Tree is the stronger model when the goal is actionable customer retention insights."""

import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(14, 4))

# Panel 1: Silhouette vs F1
axes[0].bar(["K-Means", "Decision Tree"], [km_silhouette, dt_f1])
axes[0].set_title("Silhouette (K-Means) vs F1 (DT)")
axes[0].set_ylabel("Score (0–1)")
axes[0].set_ylim(0, 1)

# Panel 2: Inertia vs ROC AUC
axes[1].bar(["K-Means", "Decision Tree"], [km_inertia, dt_auc])
axes[1].set_title("Inertia (K-Means) vs ROC AUC (DT)")
axes[1].set_ylabel("Value")
axes[1].text(0, km_inertia, "↓ better", ha="center", va="bottom", fontsize=8)

# Panel 3: Cluster Balance vs Recall
axes[2].bar(["K-Means", "Decision Tree"], [cluster_balance, dt_recall_churn])
axes[2].set_title("Cluster Balance (K) vs Recall (DT)")
axes[2].set_ylabel("Score (0–1)")
axes[2].set_ylim(0, 1)

plt.tight_layout()
plt.show()

"""Panel 1 – Silhouette (K-Means) vs F1 (Decision Tree):
K-Means achieved a relatively low silhouette score, showing weak separation between clusters, while the Decision Tree reached a perfect F1 score of 1.0. This indicates that the Decision Tree provided far stronger predictive performance for churn than clustering could.

Panel 2 – Inertia (K-Means) vs ROC AUC (Decision Tree):
K-Means produced a high inertia value (~3500), meaning clusters were not tightly grouped, whereas the Decision Tree achieved a perfect ROC AUC of 1.0, fully separating churners from retained customers. This demonstrates that the Decision Tree was much more effective at finding decision boundaries relevant to retention.

Panel 3 – Cluster Balance (K-Means) vs Recall (Decision Tree):
K-Means formed reasonably balanced clusters (~0.82 ratio), but the Decision Tree achieved perfect recall, catching all churners without missing any. This shows that while clustering is useful for exploratory grouping, the Decision Tree is the clear winner when the goal is predicting churn to drive retention strategies.
"""

# Download the Google Sheet as a CSV
sheet_id = '1lQy6kffOl3_fFpO03g82FngK-00BvT0E0T4tyM_3Hxk'
sheet_name = 'customer_segmentation_data'
url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'

customer = pd.read_csv(url)

# Display basic summary statistics
display(customer.info())

